{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c68d73",
   "metadata": {},
   "source": [
    "# Introduction to pytorch models\n",
    "\n",
    "## Introduction to autodiff\n",
    "\n",
    "Load needed libraries\n",
    "$\\newcommand\\p[1]{{\\left(#1\\right)}}$\n",
    "$\\newcommand\\code[1]{\\texttt{#1}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40f96377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712488e",
   "metadata": {},
   "source": [
    "Here is a simple example of how to find the minimum of the function\n",
    "$x\\mapsto\\p{x-3}^2$ using the autodiff functionality of Pytorch.\n",
    "\n",
    "First initialize a tensor `x` and indicate that we want to store a\n",
    "gradient on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2b2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d60da9",
   "metadata": {},
   "source": [
    "Create an optimizer on parameters. Here we want to optimize w.r.t.\n",
    "variable `x`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c44b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([x], lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf264cc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Create a computational graph using parameters (here only `x`) and\n",
    "potentially other tensors.\n",
    "\n",
    "Here we only want to compute $\\p{x-3}^2$ so we define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d956b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (x - 3) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c2ff0",
   "metadata": {},
   "source": [
    "Back-propagating gradients for `y` down to `x`. Don't forget to\n",
    "reset gradients before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c5f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcba3fc",
   "metadata": {},
   "source": [
    "Use gradient on `x` to apply a one-step gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f4d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0400], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.step()\n",
    "x.grad\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c3035",
   "metadata": {},
   "source": [
    "And last we iterate the whole process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498a0955",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, x: 1.079200, loss: 3.841600\n",
      "Iteration: 20, x: 1.717659, loss: 1.712203\n",
      "Iteration: 40, x: 2.143898, loss: 0.763130\n",
      "Iteration: 60, x: 2.428460, loss: 0.340127\n",
      "Iteration: 80, x: 2.618435, loss: 0.151595\n",
      "Iteration: 100, x: 2.745265, loss: 0.067566\n",
      "Iteration: 120, x: 2.829937, loss: 0.030114\n",
      "Iteration: 140, x: 2.886464, loss: 0.013422\n",
      "Iteration: 160, x: 2.924203, loss: 0.005982\n",
      "Iteration: 180, x: 2.949397, loss: 0.002666\n",
      "Iteration: 200, x: 2.966217, loss: 0.001188\n",
      "Iteration: 220, x: 2.977446, loss: 0.000530\n",
      "Iteration: 240, x: 2.984942, loss: 0.000236\n",
      "Iteration: 260, x: 2.989947, loss: 0.000105\n",
      "Iteration: 280, x: 2.993289, loss: 0.000047\n",
      "Iteration: 300, x: 2.995519, loss: 0.000021\n",
      "Iteration: 320, x: 2.997009, loss: 0.000009\n",
      "Iteration: 340, x: 2.998003, loss: 0.000004\n",
      "Iteration: 360, x: 2.998667, loss: 0.000002\n",
      "Iteration: 380, x: 2.999110, loss: 0.000001\n",
      "Iteration: 400, x: 2.999406, loss: 0.000000\n",
      "Iteration: 420, x: 2.999603, loss: 0.000000\n",
      "Iteration: 440, x: 2.999735, loss: 0.000000\n",
      "Iteration: 460, x: 2.999823, loss: 0.000000\n",
      "Iteration: 480, x: 2.999882, loss: 0.000000\n",
      "Iteration: 500, x: 2.999921, loss: 0.000000\n",
      "Iteration: 520, x: 2.999948, loss: 0.000000\n",
      "Iteration: 540, x: 2.999965, loss: 0.000000\n",
      "Iteration: 560, x: 2.999976, loss: 0.000000\n",
      "Iteration: 580, x: 2.999984, loss: 0.000000\n",
      "Iteration: 600, x: 2.999989, loss: 0.000000\n",
      "Iteration: 620, x: 2.999994, loss: 0.000000\n",
      "Iteration: 640, x: 2.999994, loss: 0.000000\n",
      "Iteration: 660, x: 2.999994, loss: 0.000000\n",
      "Iteration: 680, x: 2.999994, loss: 0.000000\n",
      "Iteration: 700, x: 2.999994, loss: 0.000000\n",
      "Iteration: 720, x: 2.999994, loss: 0.000000\n",
      "Iteration: 740, x: 2.999994, loss: 0.000000\n",
      "Iteration: 760, x: 2.999994, loss: 0.000000\n",
      "Iteration: 780, x: 2.999994, loss: 0.000000\n",
      "Iteration: 800, x: 2.999994, loss: 0.000000\n",
      "Iteration: 820, x: 2.999994, loss: 0.000000\n",
      "Iteration: 840, x: 2.999994, loss: 0.000000\n",
      "Iteration: 860, x: 2.999994, loss: 0.000000\n",
      "Iteration: 880, x: 2.999994, loss: 0.000000\n",
      "Iteration: 900, x: 2.999994, loss: 0.000000\n",
      "Iteration: 920, x: 2.999994, loss: 0.000000\n",
      "Iteration: 940, x: 2.999994, loss: 0.000000\n",
      "Iteration: 960, x: 2.999994, loss: 0.000000\n",
      "Iteration: 980, x: 2.999994, loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "it = 0\n",
    "while it < 1000:\n",
    "    loss = (x - 3) ** 2\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if it % 20 == 0:\n",
    "        print('Iteration: %d, x: %f, loss: %f' % (it, x.item(), loss.item()))\n",
    "    it += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc935ff",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Differentiate the exponential\n",
    "\n",
    "The exponential function can be approximated using its Taylor\n",
    "expansion:\n",
    "$\n",
    "\\exp\\p{z}\\approx\\sum_{k=0}^{N}\\frac{z^k}{k!}\n",
    "$\n",
    "\n",
    "First define `x`, the \"parameter\" and build a computational graph from\n",
    "it to compute the exponential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2997ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <answer>\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "exp = 0\n",
    "niter = 10\n",
    "it = 0\n",
    "fact = 1\n",
    "while it < niter:\n",
    "    exp += x ** it / fact\n",
    "    it += 1\n",
    "    fact *= it\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cb8e0",
   "metadata": {},
   "source": [
    "Compute the gradient and verify that it is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca96dcc3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.7183])\n"
     ]
    }
   ],
   "source": [
    "# <answer>\n",
    "exp.backward()\n",
    "print(x.grad)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9b253",
   "metadata": {},
   "source": [
    "## Solving equations with Pytorch\n",
    "\n",
    "Suppose we want to solve the following system of two equations\n",
    "\\\\[$\n",
    "e^{-e^{-(x_1 + x_2)}} = x_2 (1 + x_1^2)$\n",
    "\\\\]\n",
    "\\\\[\n",
    "$x_1 \\cos(x_2) + x_2 \\sin(x_1) = 1/2$\n",
    "\\\\]\n",
    "\n",
    "Find a loss whose optimization leads to a solution of the system of\n",
    "equations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef855d03",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define two functions\n",
    "# <answer>\n",
    "def f1(x1, x2):\n",
    "    return torch.exp(-torch.exp(-(x1 + x2))) - x2 * (1 + x1 ** 2)\n",
    "\n",
    "\n",
    "def f2(x1, x2):\n",
    "    return x1 * torch.cos(x2) + x2 * torch.sin(x1) - 0.5\n",
    "\n",
    "x1 = torch.tensor([0.0], requires_grad=True)\n",
    "x2 = torch.tensor([0.0], requires_grad=True)\n",
    "loss = f1(x1, x2) ** 2 + f2(x1, x2) ** 2\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159c12a",
   "metadata": {},
   "source": [
    "Use Pytorch autodiff to solve the system of equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e422a60",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, x1: 0.007293, x2: 0.004651, loss: 0.385335\n",
      "Iteration: 20, x1: 0.134238, x2: 0.107664, loss: 0.250012\n",
      "Iteration: 40, x1: 0.229074, x2: 0.214341, loss: 0.146439\n",
      "Iteration: 60, x1: 0.294770, x2: 0.309024, loss: 0.078318\n",
      "Iteration: 80, x1: 0.335219, x2: 0.384967, loss: 0.040020\n",
      "Iteration: 100, x1: 0.356608, x2: 0.442270, loss: 0.020582\n",
      "Iteration: 120, x1: 0.365716, x2: 0.484327, loss: 0.010968\n",
      "Iteration: 140, x1: 0.368040, x2: 0.515040, loss: 0.006060\n",
      "Iteration: 160, x1: 0.367179, x2: 0.537610, loss: 0.003429\n",
      "Iteration: 180, x1: 0.365141, x2: 0.554350, loss: 0.001966\n",
      "Iteration: 200, x1: 0.362903, x2: 0.566874, loss: 0.001134\n",
      "Iteration: 220, x1: 0.360872, x2: 0.576303, loss: 0.000656\n",
      "Iteration: 240, x1: 0.359175, x2: 0.583435, loss: 0.000380\n",
      "Iteration: 260, x1: 0.357814, x2: 0.588844, loss: 0.000221\n",
      "Iteration: 280, x1: 0.356749, x2: 0.592954, loss: 0.000128\n",
      "Iteration: 300, x1: 0.355924, x2: 0.596081, loss: 0.000074\n",
      "Iteration: 320, x1: 0.355290, x2: 0.598461, loss: 0.000043\n",
      "Iteration: 340, x1: 0.354805, x2: 0.600274, loss: 0.000025\n",
      "Iteration: 360, x1: 0.354435, x2: 0.601656, loss: 0.000015\n",
      "Iteration: 380, x1: 0.354152, x2: 0.602708, loss: 0.000008\n",
      "Iteration: 400, x1: 0.353937, x2: 0.603511, loss: 0.000005\n",
      "Iteration: 420, x1: 0.353773, x2: 0.604122, loss: 0.000003\n",
      "Iteration: 440, x1: 0.353648, x2: 0.604588, loss: 0.000002\n",
      "Iteration: 460, x1: 0.353552, x2: 0.604943, loss: 0.000001\n",
      "Iteration: 480, x1: 0.353480, x2: 0.605214, loss: 0.000001\n",
      "Iteration: 500, x1: 0.353424, x2: 0.605420, loss: 0.000000\n",
      "Iteration: 520, x1: 0.353382, x2: 0.605577, loss: 0.000000\n",
      "Iteration: 540, x1: 0.353350, x2: 0.605697, loss: 0.000000\n",
      "Iteration: 560, x1: 0.353325, x2: 0.605789, loss: 0.000000\n",
      "Iteration: 580, x1: 0.353307, x2: 0.605858, loss: 0.000000\n",
      "Iteration: 600, x1: 0.353292, x2: 0.605912, loss: 0.000000\n",
      "Iteration: 620, x1: 0.353281, x2: 0.605952, loss: 0.000000\n",
      "Iteration: 640, x1: 0.353273, x2: 0.605983, loss: 0.000000\n",
      "Iteration: 660, x1: 0.353267, x2: 0.606006, loss: 0.000000\n",
      "Iteration: 680, x1: 0.353262, x2: 0.606024, loss: 0.000000\n",
      "Iteration: 700, x1: 0.353258, x2: 0.606038, loss: 0.000000\n",
      "Iteration: 720, x1: 0.353256, x2: 0.606048, loss: 0.000000\n",
      "Iteration: 740, x1: 0.353254, x2: 0.606056, loss: 0.000000\n",
      "Iteration: 760, x1: 0.353252, x2: 0.606062, loss: 0.000000\n",
      "Iteration: 780, x1: 0.353251, x2: 0.606067, loss: 0.000000\n",
      "Iteration: 800, x1: 0.353250, x2: 0.606071, loss: 0.000000\n",
      "Iteration: 820, x1: 0.353249, x2: 0.606073, loss: 0.000000\n",
      "Iteration: 840, x1: 0.353249, x2: 0.606075, loss: 0.000000\n",
      "Iteration: 860, x1: 0.353248, x2: 0.606076, loss: 0.000000\n",
      "Iteration: 880, x1: 0.353248, x2: 0.606078, loss: 0.000000\n",
      "Iteration: 900, x1: 0.353248, x2: 0.606079, loss: 0.000000\n",
      "Iteration: 920, x1: 0.353247, x2: 0.606079, loss: 0.000000\n",
      "Iteration: 940, x1: 0.353247, x2: 0.606079, loss: 0.000000\n",
      "Iteration: 960, x1: 0.353247, x2: 0.606079, loss: 0.000000\n",
      "Iteration: 980, x1: 0.353247, x2: 0.606079, loss: 0.000000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.7881393432617188e-06, 7.152557373046875e-07)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <answer>\n",
    "optimizer = optim.SGD([x1, x2], lr=0.01)\n",
    "\n",
    "it = 0\n",
    "while it < 1000:\n",
    "    loss = f1(x1, x2) ** 2 + f2(x1, x2) ** 2\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if it % 20 == 0:\n",
    "        print('Iteration: %d, x1: %f, x2: %f, loss: %f' % (it, x1.item(), x2.item(), loss.item()))\n",
    "    it += 1\n",
    "\n",
    "f1(x1, x2).item(), f2(x1, x2).item()\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91765e1f",
   "metadata": {},
   "source": [
    "## Linear least squares Pytorch implementation\n",
    "\n",
    "Every model in Pytorch is implemented as a class that derives from\n",
    "`nn.Module`. The two main methods to implement are:\n",
    "\n",
    "- `__init__`: Declare needed building blocks to implement forward pass\n",
    "- `forward`: Implement the forward pass from the input given as\n",
    "  argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "359c07d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LinearLeastSquare(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearLeastSquare, self).__init__()\n",
    "\n",
    "        # Declaring neural networks building blocks. Here we only need\n",
    "        # a linear transform.\n",
    "        # <answer>\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "        # </answer>\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Implementing forward pass. Return corresponding output for\n",
    "        # this neural network.\n",
    "        # <answer>\n",
    "        return self.linear(input)\n",
    "        # </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc4f58",
   "metadata": {},
   "source": [
    "## Synthetic data\n",
    "\n",
    "We use the following linear model:\n",
    "\n",
    "\\\\[\n",
    "y = \\langle\\beta,x\\rangle+\\varepsilon\n",
    "\\\\]\n",
    "\n",
    "where \\\\(x\\in\\mathcal R^p\\\\) and \\\\(\\varepsilon\\sim\\mathcal N(0, \\sigma^2)\\\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6924c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "p = 512\n",
    "N = 50000\n",
    "X = torch.randn(N, p)\n",
    "beta = torch.randn(p, 1) / math.sqrt(p)\n",
    "y = torch.mm(X, beta) + 0.5 * torch.randn(N, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58380e5",
   "metadata": {},
   "source": [
    "## Preparing dataset to feed Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2c0b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Gather data coming from Pytorch tensors using `TensorDataset`\n",
    "# <answer>\n",
    "dataset = TensorDataset(X, y)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a474ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# Define `train_loader` that is an iterable on mini-batches using\n",
    "# `DataLoader`\n",
    "# <answer>\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12678afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function to use\n",
    "from torch.nn import MSELoss\n",
    "# <answer>\n",
    "loss_fn = MSELoss()\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bc45f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization algorithm\n",
    "from torch.optim import SGD\n",
    "\n",
    "# Instantiate model with `LinearLeastSquare` with the correct input\n",
    "# size.\n",
    "# <answer>\n",
    "model = LinearLeastSquare(p)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b24d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the stochastic gradient descent algorithm with a learning rate of\n",
    "# 0.01 and a momentum of 0.9.\n",
    "# <answer>\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=.9)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da27ca",
   "metadata": {},
   "source": [
    "## Learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa8bfe23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10: Last loss: 0.6113588213920593\n",
      "Epoch 1/10: Last loss: 0.38930901885032654\n",
      "Epoch 2/10: Last loss: 0.39413878321647644\n",
      "Epoch 3/10: Last loss: 0.4637220501899719\n",
      "Epoch 4/10: Last loss: 0.407325804233551\n",
      "Epoch 5/10: Last loss: 0.3546220064163208\n",
      "Epoch 6/10: Last loss: 0.3435727059841156\n",
      "Epoch 7/10: Last loss: 0.42435112595558167\n",
      "Epoch 8/10: Last loss: 0.3953465223312378\n",
      "Epoch 9/10: Last loss: 0.4599045217037201\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    for src, tgt in train_loader:\n",
    "        # Forward pass\n",
    "        # <answer>\n",
    "        prd = model(src)\n",
    "        # </answer>\n",
    "\n",
    "        # Backpropagation on loss\n",
    "        # <answer>\n",
    "        loss = loss_fn(prd, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # </answer>\n",
    "\n",
    "        # Gradient descent step\n",
    "        # <answer>\n",
    "        optimizer.step()\n",
    "        # </answer>\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch {i}/{epochs}: Last loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72e78b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1659e4c10>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(losses)) / len(losses) * epochs\n",
    "plt.plot(x, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d822990",
   "metadata": {},
   "source": [
    "From the model what should be the minimum MSE?\n",
    "<answer>\n",
    "Noise distribution is \\\\(\\varepsilon\\sim\\matcal\\p{0, 0.25}\\\\) so the\n",
    "minimum MSE should be \\\\(\\mathcal E\\p{\\epsilon^2}=0.25\\\\).\n",
    "</answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddbabfd",
   "metadata": {},
   "source": [
    "## Learning loop with scheduler\n",
    "\n",
    "From convex optimization theory the learning rate should be decreasing\n",
    "toward 0. To have something approaching we use a scheduler that is\n",
    "updating the learning rate every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daba44cb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "# Define a scheduler\n",
    "# <answer>\n",
    "model = LinearLeastSquare(p)\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=.9)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[3, 6], gamma=0.2)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207acff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Implement the learning loop with a scheduler\n",
    "# <answer>\n",
    "epochs = 10\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    for src, tgt in train_loader:\n",
    "        # Forward pass\n",
    "        prd = model(src)\n",
    "\n",
    "        # Backpropagation on loss\n",
    "        loss = loss_fn(prd, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {i}/{epochs}: Last loss: {loss}\")\n",
    "\n",
    "x = np.arange(len(losses)) / len(losses) * epochs\n",
    "plt.plot(x, losses)\n",
    "# </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965560f",
   "metadata": {},
   "source": [
    "## Multi-layer perceptron\n",
    "\n",
    "Implement a multi-layer perceptron described by the following\n",
    "function:\n",
    "\\\\[\n",
    "f\\p{x,\\beta}=W_3\\sigma\\p{W_2\\sigma{W_1 x}}\n",
    "\\\\]\n",
    "where \\\\(\\sigma\\p{x}=\\max\\p{x, 0}\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc9ee3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        # Define hyperparameters of neural network and building blocks\n",
    "        # <answer>\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size1 = hidden_size1\n",
    "        self.hidden_size2 = hidden_size2\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size, self.hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(self.hidden_size1, self.hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(self.hidden_size2, self.output_size)\n",
    "        # </answer>\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement forward pass\n",
    "        # <answer>\n",
    "        hidden = self.fc1(x)\n",
    "        relu1 = self.relu1(hidden)\n",
    "        hidden2 = self.fc2(relu1)\n",
    "        relu2 = self.relu2(hidden2)\n",
    "        output = self.fc3(relu2)\n",
    "        return output\n",
    "        # </answer>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047aaeaf",
   "metadata": {},
   "source": [
    "## Synthetic 2-dimensional spiral dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "n_loops = 2\n",
    "n_samples = 1500\n",
    "\n",
    "def spirals(n_classes=3, n_samples=1500, n_loops=2):\n",
    "    klass = np.random.choice(n_classes, n_samples)\n",
    "    radius = np.random.rand(n_samples)\n",
    "    theta = klass * 2 * math.pi / n_classes + radius * 2 * math.pi * n_loops\n",
    "    radius = radius + 0.05 * np.random.randn(n_samples)\n",
    "    return np.column_stack((radius * np.cos(theta), radius * np.sin(theta))).astype(\"float32\"), klass\n",
    "\n",
    "X_, y_ = spirals(n_samples=n_samples, n_classes=n_classes, n_loops=n_loops)\n",
    "plt.scatter(X_[:, 0], X_[:, 1], c=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757719ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "X = torch.from_numpy(X_)\n",
    "y = torch.from_numpy(y_)\n",
    "dataset = TensorDataset(X, y)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaaa8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_ = spirals(n_samples=1000, n_classes=n_classes, n_loops=n_loops)\n",
    "X = torch.from_numpy(X_)\n",
    "y = torch.from_numpy(y_)\n",
    "test_set = TensorDataset(X, y)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bca2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerPerceptron(2, 20, 20, n_classes)\n",
    "optimizer = SGD(model.parameters(), lr=0.05)\n",
    "# optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "epochs = 1000\n",
    "losses = []\n",
    "models = []\n",
    "for i in range(epochs):\n",
    "    for src, tgt in train_loader:\n",
    "        # <answer>\n",
    "        prd = model(src)\n",
    "        loss = loss_fn(prd, tgt)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        # </answer>\n",
    "\n",
    "    # Accuracy on the test set\n",
    "    acc = 0.\n",
    "    for src, tgt in test_loader:\n",
    "        prd = model(src).detach().argmax(dim=1)\n",
    "        acc += sum(prd == tgt).item()\n",
    "\n",
    "    acc /= len(test_set)\n",
    "    print(f\"Epoch {i}/{epochs}: Test accuracy: {acc}\")\n",
    "\n",
    "    models.append(copy.deepcopy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520d4ae7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_image_data(model, colors, xs, ys):\n",
    "    \"\"\"Return color image of size H*W*4.\"\"\"\n",
    "\n",
    "    # Generate points in grid\n",
    "    xx, yy = np.meshgrid(xs, ys)\n",
    "    points = np.column_stack((xx.ravel(), yy.ravel())).astype(\"float32\")\n",
    "    points = torch.from_numpy(points)\n",
    "\n",
    "    # Predict class probability on points\n",
    "    prd = model(points).detach()\n",
    "    prd = torch.nn.functional.softmax(prd, dim=1)\n",
    "\n",
    "    # Build a color image from colors\n",
    "    colors = torch.from_numpy(colors)\n",
    "    img = torch.mm(prd, colors).numpy()\n",
    "    img = img.reshape((ynum, xnum, 4))\n",
    "    img = np.minimum(img, 1)\n",
    "\n",
    "    return img\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Get n_classes colors in RGBa form\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = prop_cycle.by_key()[\"color\"]\n",
    "import matplotlib as mpl\n",
    "colors = mpl.colors.to_rgba_array(colors)[:n_classes, :4].astype(\"float32\")\n",
    "\n",
    "# Draw scatter plot of test set using colors\n",
    "ax.scatter(X[:, 0], X[:, 1], c=colors[y])\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xnum, ynum = (int(i) for i in fig.dpi * fig.get_size_inches())\n",
    "\n",
    "# Create discretization\n",
    "xs = np.linspace(xmin, xmax, xnum)\n",
    "ys = np.linspace(ymin, ymax, ynum)\n",
    "img = get_image_data(model, colors, xs, ys)\n",
    "\n",
    "ax.imshow(img, extent=[xmin, xmax, ymin, ymax], origin=\"lower\", alpha=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <answer>\n",
    "def plot_decision_region(ax, model):\n",
    "    # Build input\n",
    "    fig = ax.get_figure()\n",
    "    xnum, ynum = (int(i) for i in fig.dpi * fig.get_size_inches())\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    xx, yy = np.meshgrid(np.linspace(xmin, xmax, xnum), np.linspace(ymin, ymax, ynum))\n",
    "    points = np.column_stack((xx.ravel(), yy.ravel())).astype(\"float32\")\n",
    "\n",
    "    points = torch.from_numpy(points)\n",
    "    prd = model(points).detach()\n",
    "\n",
    "    prd = torch.nn.functional.softmax(prd, dim=1)\n",
    "\n",
    "    prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "    colors = prop_cycle.by_key()[\"color\"]\n",
    "    import matplotlib as mpl\n",
    "    colors = torch.from_numpy(mpl.colors.to_rgba_array(colors)[:prd.size(1), :3].astype(\"float32\"))\n",
    "    img = torch.mm(prd, colors).numpy()\n",
    "\n",
    "    img = img.reshape((ynum, xnum, 3))\n",
    "\n",
    "    ax.imshow(img, extent=[xmin, xmax, ymin, ymax], zorder=0, origin=\"lower\", alpha=.7)\n",
    "    return img\n",
    "\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = np.array(prop_cycle.by_key()[\"color\"])[:n_classes]\n",
    "colors_rgb = mpl.colors.to_rgba_array(colors).astype(\"float32\")\n",
    "mean_color = np.minimum(np.mean(colors_rgb, axis=0), 1)\n",
    "\n",
    "X, y = spirals(n_samples=900, n_loops=n_loops, n_classes=n_classes)\n",
    "ax.scatter(X[:, 0], X[:, 1], c=colors[y])\n",
    "xnum, ynum = (int(i) for i in fig.dpi * fig.get_size_inches())\n",
    "xmin, xmax = ax.get_xlim()\n",
    "ymin, ymax = ax.get_ylim()\n",
    "xs = np.linspace(xmin, xmax, xnum)\n",
    "ys = np.linspace(ymin, ymax, ynum)\n",
    "\n",
    "im = ax.imshow(\n",
    "    np.tile(mean_color, (ynum, xnum, 1)),\n",
    "    extent=[xmin, xmax, ymin, ymax],\n",
    "    origin=\"lower\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "def animate(i):\n",
    "    model = models[i]\n",
    "    data = get_image_data(model, colors_rgb, xs, ys)\n",
    "\n",
    "    im.set_data(data)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(\n",
    "    fig=fig,\n",
    "    func=animate,\n",
    "    frames=range(len(models)),\n",
    "    interval=50,\n",
    "    blit=True\n",
    ")\n",
    "\n",
    "ani.save('test_anim.mp4', fps=50)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "X, y = spirals(n_samples=900, n_loops=n_loops, n_classes=n_classes)\n",
    "\n",
    "prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "colors = np.array(prop_cycle.by_key()[\"color\"])\n",
    "\n",
    "ax.scatter(X[:, 0], X[:, 1], c=colors[y])\n",
    "img = plot_decision_region(ax, model)\n",
    "plt.show()\n",
    "# </answer>"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
